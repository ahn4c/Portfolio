{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from urlparse import urljoin\n",
    "import urllib\n",
    "import urllib2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.viamichelin.com/web/Restaurants/Restaurants-United_States?page=1'\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def michelin_restaurant_name (soup):\n",
    "    name = []\n",
    "    for row in soup.findAll('div', {'class':'poi-item-name truncate'}):\n",
    "        try:\n",
    "            name.append(row.getText().strip('\\n'))\n",
    "            \n",
    "        except:\n",
    "            name.append(\"NA\")\n",
    "    return name\n",
    "\n",
    "def address (soup):\n",
    "    address = []\n",
    "    for row in soup.findAll('div', {'class':'poi-item-address truncate'}):\n",
    "        try:\n",
    "            address.append(row.getText().strip('\\n').strip('\\t').strip('\\n'))\n",
    "            \n",
    "        except:\n",
    "            address.append(\"NA\")\n",
    "    return address\n",
    "\n",
    "def stars (soup):\n",
    "    star = []\n",
    "    for row in soup.findAll(lambda tag: tag.name == 'span' and tag.get('class') == ['poi-item-stars']):\n",
    "        count = 0\n",
    "        try:\n",
    "            for cnt in row.findAll('span', {'class':'star'}):\n",
    "                count = count+1\n",
    "            star.append(count)\n",
    "        except:\n",
    "            star.append(count)\n",
    "    return star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for page in range(1,72):\n",
    "    url = 'https://www.viamichelin.com/web/Restaurants/Restaurants-United_States?page='+str(page)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "    name_df = pd.DataFrame(michelin_restaurant_name(soup), columns = ['Restaurant_Name'])\n",
    "    address_df= pd.DataFrame(address(soup), columns = ['Address'])\n",
    "    star_df = pd.DataFrame(stars(soup), columns = ['Stars'])\n",
    "    aggregate = pd.concat([name_df, address_df, star_df], axis = 1)\n",
    "    results = results.append(aggregate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\Michelin_Restaurants.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gayot\n",
    "location = 'NY'\n",
    "page = 0\n",
    "gayot_url = 'http://www.gayot.com/restaurants/searchresult.php?search=&rating=13&code=NY&start=50&jump='\n",
    "r = requests.get(gayot_url)\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gayot_restaurant_name(soup):\n",
    "    name = []\n",
    "    for row in soup.findAll('a', {'class':'hoveru'}):\n",
    "        try:\n",
    "            name.append(row.getText())\n",
    "            \n",
    "        except:\n",
    "            name.append(\"NA\")\n",
    "    return name\n",
    "\n",
    "def gayot_rating(soup):\n",
    "    rating = []\n",
    "    \n",
    "    for row in soup.findAll('td', {'width': '100'}):\n",
    "        try:\n",
    "            if row.find('strong').getText() is not None:\n",
    "                #Orginal format was '13/20'. Pulled out score and convert to float\n",
    "                rating.append(float(row.find('strong').getText()[0:2]))\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return rating\n",
    "\n",
    "def gayot_address(soup):\n",
    "    address = []\n",
    "    for row in soup.findAll('td', {'width': '278'}):\n",
    "        try:\n",
    "            #Pull address and remove extra tags/characters\n",
    "            address.append(row.getText()[2:len(row.getText())-11])\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gayot_address(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for city in ['NY']: #Come back and do NY, 140 for CH, 760 for NY\n",
    "    for rating in range(12,21): #Start with rating 12 as 10 and 11 are too low for Michelin\n",
    "        for page in range(0,760,10): #The max number of listings per rating per city is 762 (NY with rating 13)\n",
    "            gayot_url = 'http://www.gayot.com/restaurants/searchresult.php?search=&rating='+str(rating)+'&code='+str(city)+'&start='+str(page)+'&jump='\n",
    "            r = requests.get(gayot_url)\n",
    "            soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "            name_df = pd.DataFrame(gayot_restaurant_name(soup), columns = ['Restaurant_Name'])\n",
    "            address_df= pd.DataFrame(gayot_address(soup), columns = ['Address'])\n",
    "            rating_df = pd.DataFrame(gayot_rating(soup), columns = ['Rating'])\n",
    "            aggregate = pd.concat([name_df, address_df, rating_df], axis = 1)\n",
    "            results = results.append(aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\NY_Gayot_Restaurants.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zagat_url = 'https://www.zagat.com/p/washington-dc#filter/addr_city=Washington&score5_food=4.0&vertical=46&orderby=score_food&sort=desc&page=2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(zagat_url)\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "\n",
    "def zagat_restaurant_name (soup):\n",
    "    name = []\n",
    "    for row in soup.findAll('span', {'class':'content-card__link js-hover-apply'}):\n",
    "        try:\n",
    "            name.append(row.getText())\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return name\n",
    "\n",
    "def zagat_rating(soup):\n",
    "    rating = []\n",
    "    \n",
    "    for row in soup.findAll('td', {'width': '100'}):\n",
    "        try:\n",
    "            if row.find('strong').getText() is not None:\n",
    "                #Orginal format was '13/20'. Pulled out score and convert to float\n",
    "                rating.append(float(row.find('strong').getText()[0:2]))\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import urllib\n",
    "import sqlite3\n",
    "\n",
    "sf = pd.DataFrame()\n",
    "for page in range(1, 50):\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1021&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    sf = sf.append(cityadd)\n",
    "\n",
    "sf = sf.reset_index()\n",
    "del sf['index']\n",
    "\n",
    "ny = pd.DataFrame()\n",
    "for page in range(1, 50):\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1020&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    ny = ny.append(cityadd)\n",
    "\n",
    "ny = ny.reset_index()\n",
    "del ny['index']\n",
    "\n",
    "#Get fewer cities for CH and DC as they are smaller cities. Don't want too much class imbalance\n",
    "ch = pd.DataFrame()\n",
    "for page in range(1, 25):\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1013&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    ch = ch.append(cityadd)\n",
    "\n",
    "ch = ch.reset_index()\n",
    "del ch['index']\n",
    "\n",
    "dc = pd.DataFrame()\n",
    "for page in range(1, 25):\n",
    "    #zagat_url= \"https://www.zagat.com/proxy/v1.4?addr_city=Washington&score5_food=4.0&vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1024&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1024&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    dc = dc.append(cityadd)\n",
    "\n",
    "dc = dc.reset_index()\n",
    "del dc['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['title', 'cuisine', 'cost', 'price_level', 'food_rating', 'decor_rating', 'service_rating']\n",
    "sf = sf[columns]\n",
    "ny = ny[columns]\n",
    "ch = ch[columns]\n",
    "dc = dc[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\NY_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')\n",
    "sf.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\SF_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')\n",
    "ch.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\CH_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')\n",
    "dc.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\DC_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read, standardize and join csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny_gayot = pd.read_csv('NY_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "sf_gayot = pd.read_csv('SF_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "ch_gayot = pd.read_csv('CH_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "dc_gayot = pd.read_csv('DC_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "ny_zagat = pd.read_csv('NY_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "sf_zagat = pd.read_csv('SF_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "ch_zagat = pd.read_csv('CH_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "dc_zagat = pd.read_csv('DC_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "\n",
    "michelin = pd.read_csv('Michelin_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "award = pd.read_csv('James_Beard_Awards.csv')\n",
    "\n",
    "ny_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "ch_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "sf_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "dc_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "ny_gayot['Restaurant_Name'] = ny_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "ch_gayot['Restaurant_Name'] = ch_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "sf_gayot['Restaurant_Name'] = sf_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "dc_gayot['Restaurant_Name'] = dc_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "ny_zagat['Restaurant_Name'] = ny_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "ch_zagat['Restaurant_Name'] = ch_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "dc_zagat['Restaurant_Name'] = dc_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "sf_zagat['Restaurant_Name'] = sf_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "michelin['Restaurant_Name'] = michelin['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "award['Restaurant_Name'] = award['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "\n",
    "#Drop chain restaurants\n",
    "ny_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "ch_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "sf_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "dc_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "ny_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "ch_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "sf_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "dc_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "\n",
    "ny_gayot.reset_index(inplace=True, drop = True)\n",
    "ch_gayot.reset_index(inplace=True, drop = True)\n",
    "sf_gayot.reset_index(inplace=True, drop = True)\n",
    "dc_gayot.reset_index(inplace=True, drop = True)\n",
    "ny_zagat.reset_index(inplace=True, drop = True)\n",
    "ch_zagat.reset_index(inplace=True, drop = True)\n",
    "sf_zagat.reset_index(inplace=True, drop = True)\n",
    "dc_zagat.reset_index(inplace=True, drop = True)\n",
    "michelin.reset_index(inplace=True, drop = True)\n",
    "\n",
    "del ny_gayot['Unnamed: 0']\n",
    "del sf_gayot['Unnamed: 0']\n",
    "del ch_gayot['Unnamed: 0']\n",
    "del dc_gayot['Unnamed: 0']\n",
    "del ny_zagat['Unnamed: 0']\n",
    "del sf_zagat['Unnamed: 0']\n",
    "del ch_zagat['Unnamed: 0']\n",
    "del dc_zagat['Unnamed: 0']\n",
    "del michelin['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def zip(x):\n",
    "    return x[len(x)-5:len(x)]\n",
    "\n",
    "michelin['zip']= michelin['Address'].map(zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ny (x):\n",
    "    if (x[0]=='1'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def ch (x):\n",
    "    if (x[0]=='6') or (x=='icago'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def sf (x):\n",
    "    if (x[0] == '9'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Indicates City of the row\n",
    "michelin['ny'] = michelin['zip'].apply(ny)\n",
    "michelin['ch'] = michelin['zip'].apply(ch)\n",
    "michelin['sf'] = michelin['zip'].apply(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny = pd.merge(michelin[michelin['ny']==1], ny_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "ny = pd.merge(ny, ny_zagat, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "sf = pd.merge(michelin[michelin['sf']==1], sf_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "sf = pd.merge(sf, sf_zagat, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "ch = pd.merge(michelin[michelin['ch']==1], ch_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "ch = pd.merge(ch, ch_zagat, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "dc = pd.merge(dc_zagat, dc_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "\n",
    "ny = pd.merge(ny, award, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "sf = pd.merge(sf, award, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "ch = pd.merge(ch, award, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "dc = pd.merge(dc, award, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "\n",
    "ny['Award_Past_Three_Years'].fillna(value = 0, inplace = True)\n",
    "sf['Award_Past_Three_Years'].fillna(value = 0, inplace = True)\n",
    "ch['Award_Past_Three_Years'].fillna(value = 0, inplace = True)\n",
    "dc['Award_Past_Three_Years'].fillna(value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Drop major non-DC restaurants\n",
    "dc = dc[dc['Restaurant_Name']!='the inn at little washington']\n",
    "dc = dc[dc['Restaurant_Name']!='restaurant eve']\n",
    "dc = dc[dc['Restaurant_Name']!='chima brazilian steakhouse']\n",
    "dc = dc[dc['Restaurant_Name']!='tachibana japanese restaurant']\n",
    "\n",
    "# dc.drop_duplicates(['Restaurant_Name'], keep=False, inplace = True)\n",
    "dc.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.concat([ny,sf], ignore_index = True)[['Restaurant_Name', 'Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating', 'Award_Past_Three_Years']]\n",
    "#price_level_dummies = pd.get_dummies(train.price_level)\n",
    "#train = pd.concat([train[['Restaurant_Name', 'Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], price_level_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to impute Rating from food_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food_rating\n",
       "4.3    14.0\n",
       "4.4    14.0\n",
       "4.5    14.0\n",
       "4.6    14.0\n",
       "4.7    14.0\n",
       "4.8    16.0\n",
       "4.9    18.0\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('food_rating')['Rating'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Searching for nulls wasn't working so I had fill with a number\n",
    "import numpy as np\n",
    "train['Rating'].fillna(-5.0, inplace=True)\n",
    "\n",
    "for i in range(0,len(train)):\n",
    "    if (train.loc[i,('Rating')] == -5.0) and (train.loc[i,('food_rating')]): \n",
    "        if train.loc[i,('food_rating')] < 4.8:\n",
    "            train.loc[i,('Rating')] = 14.0 #Assume 13.5\n",
    "        elif train.loc[i,('food_rating')] == 4.8:\n",
    "            train.loc[i,('Rating')] = 16.0\n",
    "        else:\n",
    "            train.loc[i,('Rating')] = 18.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food_rating\n",
       "4.4          NaN\n",
       "4.5    13.833333\n",
       "4.6    14.307692\n",
       "4.7    14.818182\n",
       "4.8    15.500000\n",
       "4.9          NaN\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.groupby('food_rating')['Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch['Rating'].fillna(-5.0, inplace=True)\n",
    "\n",
    "for i in range(0,len(ch)):\n",
    "    if (ch.loc[i,('Rating')] == -5.0) and (ch.loc[i,('food_rating')]): \n",
    "        if ch.loc[i,('food_rating')] < 4.6:\n",
    "            ch.loc[i,('Rating')] = 13.5\n",
    "        elif ch.loc[i,('food_rating')] <4.8:\n",
    "            ch.loc[i,('Rating')] = 14.5\n",
    "        else:\n",
    "            ch.loc[i,('Rating')] = 15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food_rating\n",
       "4.3    13.666667\n",
       "4.4    13.600000\n",
       "4.5    14.133333\n",
       "4.6    14.111111\n",
       "4.7    14.800000\n",
       "4.8    14.250000\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Used mean as median doesn't give much insight. Median is 14.0 for all food_ratings\n",
    "dc.groupby('food_rating')['Rating'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dc['Rating'].fillna(-5.0, inplace=True)\n",
    "\n",
    "for i in range(0,len(dc)):\n",
    "    if (dc.loc[i,('Rating')] == -5.0) and (dc.loc[i,('food_rating')]): \n",
    "        if dc.loc[i,('food_rating')] < 4.7:\n",
    "            dc.loc[i,('Rating')] = 14.0\n",
    "#        elif dc.loc[i,('food_rating')] < 4.7:\n",
    "#            dc.loc[i,('Rating')] = 13.0 #Assume that 4.4 should be 13.0 as well\n",
    "        else:\n",
    "            dc.loc[i,('Rating')] = 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe to use for DC predictions\n",
    "#dc_price_level_dummies = pd.get_dummies(dc.price_level)\n",
    "#dc_test = pd.concat([dc[['Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], dc_price_level_dummies], axis = 1)\n",
    "dc_test = dc[['Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating', 'Award_Past_Three_Years']]\n",
    "dc_test.dropna(inplace=True)\n",
    "dc_test.reset_index(inplace =True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:14: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n"
     ]
    }
   ],
   "source": [
    "#Keep columns as \n",
    "#ch_price_level_dummies = pd.get_dummies(ch.price_level)\n",
    "#test = pd.concat([ch[['Restaurant_Name', 'Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], price_level_dummies], axis = 1)\n",
    "train.dropna(inplace = True)\n",
    "#X_train = train[['Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']]\n",
    "X_train = train[train.columns -['Restaurant_Name'] - ['Stars']]\n",
    "y_train = train['Stars']\n",
    "\n",
    "#ch_price_level_dummies = pd.get_dummies(ch.price_level)\n",
    "#test = pd.concat([ch[['Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], ch_price_level_dummies], axis = 1)\n",
    "test = ch[['Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating', 'Award_Past_Three_Years']]\n",
    "test.dropna(inplace=True)\n",
    "#train[train.columns -['Restaurant_Name'] - ['Stars']]\n",
    "X_test = test[test.columns - ['Stars']]\n",
    "#x_test = test[['Rating', 'cost', 'food_rating','decor_rating', 'service_rating','M', 'VE']]\n",
    "y_test = test['Stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Takes model.predict(dc_test) as input\n",
    "def dc_predictions (x):\n",
    "    dc_result = pd.DataFrame(x)\n",
    "    dc_result.rename(columns = {0:'predicted_stars'}, inplace=True)\n",
    "    dc_dummy = dc_test.reset_index(drop = True)\n",
    "    temp = pd.concat([dc_result, dc_dummy], axis = 1)\n",
    "    dc_final = pd.merge(dc, temp, on =['Rating','cost','food_rating','decor_rating','service_rating'] )\n",
    "    dc_final = dc_final[['Restaurant_Name', 'predicted_stars']]\n",
    "    print '\\n',dc_final[dc_final['predicted_stars'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def run_model(model):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "#     print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "#     print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "#     dc_predictions(model.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.846153846154\n",
      "Confusion Matrix \n",
      "[[61  3  1  0]\n",
      " [ 4  4  2  0]\n",
      " [ 0  1  1  0]\n",
      " [ 0  0  1  0]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.94      0.94        65\n",
      "        1.0       0.50      0.40      0.44        10\n",
      "        2.0       0.20      0.50      0.29         2\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.85      0.85      0.85        78\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(rf.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 1188 candidates, totalling 7128 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 227 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 633 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1199 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1929 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2819 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3873 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5087 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6465 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7128 out of 7128 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.871794871795\n",
      "Confusion Matrix \n",
      "[[63  2  0  0]\n",
      " [ 5  5  0  0]\n",
      " [ 0  2  0  0]\n",
      " [ 1  0  0  0]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94        65\n",
      "        1.0       0.56      0.50      0.53        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.83      0.87      0.85        78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 3,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 8}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20], 'criterion':['gini', 'entropy'], 'max_depth':[3,5,7,10,12,15], 'min_samples_split': [2,3,4], 'min_samples_leaf':[1,2,3] }\n",
    "gsrf = GridSearchCV(RandomForestClassifier(), param_grid, verbose = 2, cv= 6, n_jobs = -1)\n",
    "gsrf.fit(X_train, y_train)\n",
    "y_pred = gsrf.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "gsrf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  Restaurant_Name  predicted_stars\n",
      "5                           fiola              1.0\n",
      "10         minibar by josé andrés              3.0\n",
      "15   marcel's by robert wiedmaier              1.0\n",
      "19                          plume              1.0\n",
      "46                           komi              2.0\n",
      "53                     fiola mare              1.0\n",
      "154             sakedokoro makoto              1.0\n"
     ]
    }
   ],
   "source": [
    "rf_best = RandomForestClassifier(criterion= 'gini', max_depth= 3, min_samples_leaf= 2, min_samples_split = 3, n_estimators = 8)\n",
    "rf_best.fit(X_train, y_train)\n",
    "y_pred = rf_best.predict(X_test)\n",
    "dc_predictions(rf_best.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16762409,  0.45251412,  0.13786738,  0.12538707,  0.11660734])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>cost</th>\n",
       "      <th>decor_rating</th>\n",
       "      <th>food_rating</th>\n",
       "      <th>service_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  cost  decor_rating  food_rating  service_rating\n",
       "0    13.0  43.0           3.8          4.5             4.2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.columns -['Restaurant_Name'] - ['Stars']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.846153846154\n",
      "Confusion Matrix \n",
      "[[62  2  1  0]\n",
      " [ 5  4  0  1]\n",
      " [ 0  2  0  0]\n",
      " [ 0  0  1  0]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.95      0.94        65\n",
      "        1.0       0.50      0.40      0.44        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.84      0.85      0.84        78\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "ex = ExtraTreesClassifier()\n",
    "ex.fit(X_train, y_train)\n",
    "y_pred = ex.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(ex.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dc_predictions(ex.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20], 'criterion':['gini', 'entropy'], 'max_depth':[None,3,5,7,10,12,15], 'min_samples_split': [2,3,4,5,6], 'min_samples_leaf':[1,2,3] }\n",
    "gsex = GridSearchCV(ExtraTreesClassifier(), param_grid, verbose = 2, n_jobs = -1)\n",
    "gsex.fit(X_train, y_train)\n",
    "y_pred = gsex.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "gsex.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex_best = ExtraTreesClassifier(criterion='entropy', max_depth = 12, min_samples_leaf = 1, min_samples_split = 6, n_estimators = 9)\n",
    "ex_best.fit(X_train, y_train)\n",
    "y_pred = ex_best.predict(X_test)\n",
    "dc_predictions(ex_best.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.846153846154\n",
      "Confusion Matrix \n",
      "[[64  1  0  0]\n",
      " [ 7  2  0  1]\n",
      " [ 0  2  0  0]\n",
      " [ 0  0  1  0]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.98      0.94        65\n",
      "        1.0       0.40      0.20      0.27        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.80      0.85      0.82        78\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_rbf = svm.SVC()\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "y_pred = svm_rbf.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(svm_rbf.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.871794871795\n",
      "Confusion Matrix \n",
      "[[63  2  0  0]\n",
      " [ 5  4  1  0]\n",
      " [ 1  1  0  0]\n",
      " [ 0  0  0  1]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94        65\n",
      "        1.0       0.57      0.40      0.47        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.85      0.87      0.86        78\n",
      "\n",
      "\n",
      "                                    Restaurant_Name  predicted_stars\n",
      "0                      monocacy crossing restaurant              1.0\n",
      "1                                   rasika west end              2.0\n",
      "2                                   rasika west end              2.0\n",
      "3                                            rasika              2.0\n",
      "4                                            rasika              2.0\n",
      "5                                             fiola              2.0\n",
      "6                                          corduroy              2.0\n",
      "7                           l'auberge chez francois              2.0\n",
      "8                 fogo de chão brazilian steakhouse              2.0\n",
      "9                                             tosca              2.0\n",
      "10                           minibar by josé andrés              3.0\n",
      "11                                    the lafayette              2.0\n",
      "12                                  the bombay club              2.0\n",
      "13                                        prime rib              2.0\n",
      "14                                        pupatella              1.0\n",
      "15                     marcel's by robert wiedmaier              2.0\n",
      "16                                          red hen              2.0\n",
      "17                                         zaytinya              1.0\n",
      "18                                    rose's luxury              2.0\n",
      "19                                            plume              2.0\n",
      "21                                         menomale              1.0\n",
      "22                                     kabob palace              1.0\n",
      "23                             florida avenue grill              1.0\n",
      "24                                   mintwood place              1.0\n",
      "25                                          donburi              1.0\n",
      "26                                              sei              1.0\n",
      "27                                        lightfoot              2.0\n",
      "28                           central michel richard              2.0\n",
      "29                                 ayse meze lounge              1.0\n",
      "30                                 the tasting room              2.0\n",
      "..                                              ...              ...\n",
      "256                         takorean | the yards dc              1.0\n",
      "257                                       lyon hall              1.0\n",
      "258                           lebanese taverna cafe              1.0\n",
      "259                           lebanese taverna cafe              1.0\n",
      "260            lebanese taverna restaurant pentagon              1.0\n",
      "261            lebanese taverna restaurant pentagon              1.0\n",
      "262                al dente italian restaurant d.c.              1.0\n",
      "263                                            etto              1.0\n",
      "264                                   mari vanna dc              1.0\n",
      "265                                     pi pizzeria              1.0\n",
      "266                                     pi pizzeria              1.0\n",
      "267                                pi pizzeria - dc              1.0\n",
      "268                                pi pizzeria - dc              1.0\n",
      "269                     banana cafe &amp; piano bar              1.0\n",
      "270                                   big bear cafe              1.0\n",
      "271                 honey pig gooldaegee korean bbq              1.0\n",
      "272                                 georgia brown's              1.0\n",
      "278                                  ardeo + bardeo              1.0\n",
      "279                               sichuan jin river              1.0\n",
      "280                                           range              2.0\n",
      "281                   fire works pizza - courthouse              1.0\n",
      "282                   fire works pizza - courthouse              1.0\n",
      "283                                      fire works              1.0\n",
      "284                                      fire works              1.0\n",
      "285                               tavira restaurant              1.0\n",
      "287                                  woodward table              1.0\n",
      "288                          minerva indian cuisine              1.0\n",
      "289                               bobby van's grill              2.0\n",
      "290  mccormick &amp; schmick's seafood &amp; steaks              1.0\n",
      "291                                         bond 45              2.0\n",
      "\n",
      "[265 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "svm_l = svm.SVC(kernel = 'linear')\n",
    "svm_l.fit(X_train, y_train)\n",
    "y_pred = svm_l.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(svm_l.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_p = svm.SVC(kernel = 'poly')\n",
    "svm_p.fit(X_train, y_train)\n",
    "y_pred = svm_p.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(svm_p.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(dt.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bdt = BaggingClassifier(DecisionTreeClassifier())\n",
    "bdt.fit(X_train, y_train)\n",
    "y_pred = bdt.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(bdt.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(lr.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "kn = KNeighborsClassifier()\n",
    "kn.fit(X_train, y_train)\n",
    "y_pred = kn.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(kn.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dc_predictions(kn.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Failures...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_app_id = 'vKNIMUrgB4Q1bw9QQBrWvA'\n",
    "yelp_secret = '47e2cwloU2D3yjjn8ZNW19coWnzty42bjLpy4Nr3tKxTLb8XamT6dM5cpYdqQDUt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yelpapi import YelpAPI\n",
    "import rauth\n",
    "\n",
    "yelp_key = 'h7PhOS6JV0P-q_HBqhPcNA'\n",
    "yelp_secret = '-cvy8PzcSI-PuAa9nTifCNoPkN8'\n",
    "yelp_token = 'jOBN_KgzD6pnrkqWldAxV-bD7O5zUFLh'\n",
    "yelp_token_secret = 'ywnyhjQ6nFhUXPAl1dbSpooT5LQ'\n",
    "#yelp_api = YelpAPI(yelp_key, yelp_secret, yelp_token, yelp_token_secret)\n",
    "session = rauth.OAuth1Session(\n",
    "    consumer_key = yelp_key\n",
    "    ,consumer_secret = yelp_secret\n",
    "    ,access_token = yelp_token\n",
    "    ,access_token_secret = yelp_token_secret)\n",
    "\n",
    "params = {}\n",
    "params[\"term\"] = \"restaurant\"\n",
    "params[\"location\"] = \"San Francisco\"\n",
    "#params[\"limit\"] = 20\n",
    "request = session.get(\"http://api.yelp.com/v2/search\",params=params)\n",
    "   \n",
    "#Transforms the JSON API response into a Python dictionary\n",
    "data = request.json()\n",
    "z= pd.json_loads(data)\n",
    "#data['businesses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_url = 'https://www.yelp.com/search?find_desc=Restaurants&find_loc=Washington,+DC&start=0&sortby=rating&attrs=RestaurantsPriceRange2.2,RestaurantsPriceRange2.3,RestaurantsPriceRange2.4'\n",
    "r = requests.get(yelp_url)\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "\n",
    "def yelp_restaurant_name (soup):\n",
    "    name = []\n",
    "    for row in soup.findAll('a', {'data-analytics-label':'biz-name'}):\n",
    "        try:\n",
    "            name.append(row.getText())\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return name\n",
    "\n",
    "yelp_restaurant_name(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
