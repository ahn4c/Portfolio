{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuisine and price level suck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from urlparse import urljoin\n",
    "import urllib\n",
    "import urllib2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.viamichelin.com/web/Restaurants/Restaurants-United_States?page=1'\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def michelin_restaurant_name (soup):\n",
    "    name = []\n",
    "    for row in soup.findAll('div', {'class':'poi-item-name truncate'}):\n",
    "        try:\n",
    "            name.append(row.getText().strip('\\n'))\n",
    "            \n",
    "        except:\n",
    "            name.append(\"NA\")\n",
    "    return name\n",
    "\n",
    "def address (soup):\n",
    "    address = []\n",
    "    for row in soup.findAll('div', {'class':'poi-item-address truncate'}):\n",
    "        try:\n",
    "            address.append(row.getText().strip('\\n').strip('\\t').strip('\\n'))\n",
    "            \n",
    "        except:\n",
    "            address.append(\"NA\")\n",
    "    return address\n",
    "\n",
    "def stars (soup):\n",
    "    star = []\n",
    "    for row in soup.findAll(lambda tag: tag.name == 'span' and tag.get('class') == ['poi-item-stars']):\n",
    "        count = 0\n",
    "        try:\n",
    "            for cnt in row.findAll('span', {'class':'star'}):\n",
    "                count = count+1\n",
    "            star.append(count)\n",
    "        except:\n",
    "            star.append(count)\n",
    "    return star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for page in range(1,72):\n",
    "    url = 'https://www.viamichelin.com/web/Restaurants/Restaurants-United_States?page='+str(page)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "    name_df = pd.DataFrame(michelin_restaurant_name(soup), columns = ['Restaurant_Name'])\n",
    "    address_df= pd.DataFrame(address(soup), columns = ['Address'])\n",
    "    star_df = pd.DataFrame(stars(soup), columns = ['Stars'])\n",
    "    aggregate = pd.concat([name_df, address_df, star_df], axis = 1)\n",
    "    results = results.append(aggregate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Restaurant_Name    0\n",
       "Address            0\n",
       "Stars              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Restaurant_Name     object\n",
       "Address             object\n",
       "Stars              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1586, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\Michelin_Restaurants.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gayot\n",
    "location = 'NY'\n",
    "page = 0\n",
    "gayot_url = 'http://www.gayot.com/restaurants/searchresult.php?search=&rating=13&code=NY&start=50&jump='\n",
    "r = requests.get(gayot_url)\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gayot_restaurant_name(soup):\n",
    "    name = []\n",
    "    for row in soup.findAll('a', {'class':'hoveru'}):\n",
    "        try:\n",
    "            name.append(row.getText())\n",
    "            \n",
    "        except:\n",
    "            name.append(\"NA\")\n",
    "    return name\n",
    "\n",
    "def gayot_rating(soup):\n",
    "    rating = []\n",
    "    \n",
    "    for row in soup.findAll('td', {'width': '100'}):\n",
    "        try:\n",
    "            if row.find('strong').getText() is not None:\n",
    "                #Orginal format was '13/20'. Pulled out score and convert to float\n",
    "                rating.append(float(row.find('strong').getText()[0:2]))\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return rating\n",
    "\n",
    "def gayot_address(soup):\n",
    "    address = []\n",
    "    for row in soup.findAll('td', {'width': '278'}):\n",
    "        try:\n",
    "            #Pull address and remove extra tags/characters\n",
    "            address.append(row.getText()[2:len(row.getText())-11])\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'104 S. 4th St.Brooklyn, NY 11211',\n",
       " u'325 BoweryNew York, NY 10003',\n",
       " u'117 E. 60th St.New York, NY 100',\n",
       " u'183 W. 10th St.New York, NY 10014',\n",
       " u'502 Sixth Ave.New York, NY 10011',\n",
       " u'222 E. 58th St.New York, NY 10022',\n",
       " u'19 E. 36th St.New York, NY 10016',\n",
       " u'321 W. 46th St.New York, NY 10036',\n",
       " u'781 Franklin Ave.Brooklyn, NY 11238',\n",
       " u'186 Avenue BNew York, NY 10009']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gayot_address(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for city in ['NY']: #Come back and do NY, 140 for CH, 760 for NY\n",
    "    for rating in range(12,21): #Start with rating 12 as 10 and 11 are too low for Michelin\n",
    "        for page in range(0,760,10): #The max number of listings per rating per city is 762 (NY with rating 13)\n",
    "            gayot_url = 'http://www.gayot.com/restaurants/searchresult.php?search=&rating='+str(rating)+'&code='+str(city)+'&start='+str(page)+'&jump='\n",
    "            r = requests.get(gayot_url)\n",
    "            soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "            name_df = pd.DataFrame(gayot_restaurant_name(soup), columns = ['Restaurant_Name'])\n",
    "            address_df= pd.DataFrame(gayot_address(soup), columns = ['Address'])\n",
    "            rating_df = pd.DataFrame(gayot_rating(soup), columns = ['Rating'])\n",
    "            aggregate = pd.concat([name_df, address_df, rating_df], axis = 1)\n",
    "            results = results.append(aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2387, 3)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1562, 3)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jean-Georges</td>\n",
       "      <td>Trump International Hotel &amp; Tower New York1 Ce...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le Bernardin</td>\n",
       "      <td>The AXA Equitable Building155 W. 51st St.New Y...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masa</td>\n",
       "      <td>Time Warner Center10 Columbus Cir.New York, NY...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daniel</td>\n",
       "      <td>60 E. 65th St.New York, NY 10065 | Menu\\r\\n\\r\\...</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Per Se</td>\n",
       "      <td>Time Warner Center10 Columbus Cir.New York, NY...</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant_Name                                            Address  Rating\n",
       "1    Jean-Georges  Trump International Hotel & Tower New York1 Ce...    18.0\n",
       "2    Le Bernardin  The AXA Equitable Building155 W. 51st St.New Y...    18.0\n",
       "3            Masa  Time Warner Center10 Columbus Cir.New York, NY...    18.0\n",
       "0          Daniel  60 E. 65th St.New York, NY 10065 | Menu\\r\\n\\r\\...    19.0\n",
       "1          Per Se  Time Warner Center10 Columbus Cir.New York, NY...    19.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\NY_Gayot_Restaurants.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zagat_url = 'https://www.zagat.com/p/washington-dc#filter/addr_city=Washington&score5_food=4.0&vertical=46&orderby=score_food&sort=desc&page=2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(zagat_url)\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "\n",
    "def zagat_restaurant_name (soup):\n",
    "    name = []\n",
    "    for row in soup.findAll('span', {'class':'content-card__link js-hover-apply'}):\n",
    "        try:\n",
    "            name.append(row.getText())\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return name\n",
    "\n",
    "def zagat_rating(soup):\n",
    "    rating = []\n",
    "    \n",
    "    for row in soup.findAll('td', {'width': '100'}):\n",
    "        try:\n",
    "            if row.find('strong').getText() is not None:\n",
    "                #Orginal format was '13/20'. Pulled out score and convert to float\n",
    "                rating.append(float(row.find('strong').getText()[0:2]))\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 0, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-6f8db1983725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m        \u001b[0mdecor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score5_decor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m        \u001b[0mservice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score5_service'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m    \u001b[0mcityadd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'food_rating'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfood\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m    \u001b[0mcityadd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'decor_rating'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m    \u001b[0mcityadd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'service_rating'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2357\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2422\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2423\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2424\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2426\u001b[0m         \u001b[1;31m# check if we are modifying a copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1464\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1465\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value, check)\u001b[0m\n\u001b[0;32m   3416\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3417\u001b[0m             \u001b[1;31m# This item wasn't present, just insert at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3418\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3419\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   3517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3518\u001b[0m         block = make_block(values=value, ndim=self.ndim,\n\u001b[1;32m-> 3519\u001b[1;33m                            placement=slice(loc, loc + 1))\n\u001b[0m\u001b[0;32m   3520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3521\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[0;32m   2516\u001b[0m                      placement=placement, dtype=dtype)\n\u001b[0;32m   2517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2518\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2520\u001b[0m \u001b[1;31m# TODO: flexible with index=None and/or items=None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim, fastpath)\u001b[0m\n\u001b[0;32m     88\u001b[0m             raise ValueError('Wrong number of items passed %d, placement '\n\u001b[0;32m     89\u001b[0m                              'implies %d' % (len(self.values),\n\u001b[1;32m---> 90\u001b[1;33m                                              len(self.mgr_locs)))\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 0, placement implies 1"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import urllib\n",
    "import sqlite3\n",
    "\n",
    "sf = pd.DataFrame()\n",
    "for page in range(1, 50):\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1021&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    sf = sf.append(cityadd)\n",
    "\n",
    "sf = sf.reset_index()\n",
    "del sf['index']\n",
    "\n",
    "ny = pd.DataFrame()\n",
    "for page in range(1, 50):\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1020&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    ny = ny.append(cityadd)\n",
    "\n",
    "ny = ny.reset_index()\n",
    "del ny['index']\n",
    "\n",
    "#Get fewer cities for CH and DC as they are smaller cities. Don't want too much class imbalance\n",
    "ch = pd.DataFrame()\n",
    "for page in range(1, 25):\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1013&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    ch = ch.append(cityadd)\n",
    "\n",
    "ch = ch.reset_index()\n",
    "del ch['index']\n",
    "\n",
    "dc = pd.DataFrame()\n",
    "for page in range(1, 25):\n",
    "    #zagat_url= \"https://www.zagat.com/proxy/v1.4?addr_city=Washington&score5_food=4.0&vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1024&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1024&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    dc = dc.append(cityadd)\n",
    "\n",
    "dc = dc.reset_index()\n",
    "del dc['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['title', 'cuisine', 'cost', 'price_level', 'food_rating', 'decor_rating', 'service_rating']\n",
    "sf = sf[columns]\n",
    "ny = ny[columns]\n",
    "ch = ch[columns]\n",
    "dc = dc[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\NY_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')\n",
    "sf.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\SF_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')\n",
    "ch.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\CH_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')\n",
    "dc.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\DC_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read, standardize and join csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny_gayot = pd.read_csv('NY_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "sf_gayot = pd.read_csv('SF_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "ch_gayot = pd.read_csv('CH_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "dc_gayot = pd.read_csv('DC_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "ny_zagat = pd.read_csv('NY_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "sf_zagat = pd.read_csv('SF_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "ch_zagat = pd.read_csv('CH_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "dc_zagat = pd.read_csv('DC_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "\n",
    "michelin = pd.read_csv('Michelin_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "\n",
    "ny_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "ch_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "sf_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "dc_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "ny_gayot['Restaurant_Name'] = ny_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "ch_gayot['Restaurant_Name'] = ch_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "sf_gayot['Restaurant_Name'] = sf_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "dc_gayot['Restaurant_Name'] = dc_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "ny_zagat['Restaurant_Name'] = ny_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "ch_zagat['Restaurant_Name'] = ch_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "dc_zagat['Restaurant_Name'] = dc_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "sf_zagat['Restaurant_Name'] = sf_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "michelin['Restaurant_Name'] = michelin['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "\n",
    "#Drop chain restaurants\n",
    "ny_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "ch_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "sf_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "dc_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "ny_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "ch_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "sf_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "dc_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "\n",
    "ny_gayot.reset_index(inplace=True, drop = True)\n",
    "ch_gayot.reset_index(inplace=True, drop = True)\n",
    "sf_gayot.reset_index(inplace=True, drop = True)\n",
    "dc_gayot.reset_index(inplace=True, drop = True)\n",
    "ny_zagat.reset_index(inplace=True, drop = True)\n",
    "ch_zagat.reset_index(inplace=True, drop = True)\n",
    "sf_zagat.reset_index(inplace=True, drop = True)\n",
    "dc_zagat.reset_index(inplace=True, drop = True)\n",
    "michelin.reset_index(inplace=True, drop = True)\n",
    "\n",
    "del ny_gayot['Unnamed: 0']\n",
    "del sf_gayot['Unnamed: 0']\n",
    "del ch_gayot['Unnamed: 0']\n",
    "del dc_gayot['Unnamed: 0']\n",
    "del ny_zagat['Unnamed: 0']\n",
    "del sf_zagat['Unnamed: 0']\n",
    "del ch_zagat['Unnamed: 0']\n",
    "del dc_zagat['Unnamed: 0']\n",
    "del michelin['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def zip(x):\n",
    "    return x[len(x)-5:len(x)]\n",
    "\n",
    "michelin['zip']= michelin['Address'].map(zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ny (x):\n",
    "    if (x[0]=='1'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def ch (x):\n",
    "    if (x[0]=='6') or (x=='icago'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def sf (x):\n",
    "    if (x[0] == '9'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Indicates City of the row\n",
    "michelin['ny'] = michelin['zip'].apply(ny)\n",
    "michelin['ch'] = michelin['zip'].apply(ch)\n",
    "michelin['sf'] = michelin['zip'].apply(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny = pd.merge(michelin[michelin['ny']==1], ny_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "ny = pd.merge(ny, ny_zagat, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "sf = pd.merge(michelin[michelin['sf']==1], sf_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "sf = pd.merge(sf, sf_zagat, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "ch = pd.merge(michelin[michelin['ch']==1], ch_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "ch = pd.merge(ch, ch_zagat, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "dc = pd.merge(dc_zagat, dc_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Drop major non-DC restaurants\n",
    "dc = dc[dc['Restaurant_Name']!='the inn at little washington']\n",
    "dc = dc[dc['Restaurant_Name']!='restaurant eve']\n",
    "dc = dc[dc['Restaurant_Name']!='chima brazilian steakhouse']\n",
    "dc = dc[dc['Restaurant_Name']!='tachibana japanese restaurant']\n",
    "\n",
    "# dc.drop_duplicates(['Restaurant_Name'], keep=False, inplace = True)\n",
    "dc.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.concat([ny,sf], ignore_index = True)[['Restaurant_Name','cuisine','price_level', 'Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']]\n",
    "train_price_level_dummies = pd.get_dummies(train.price_level)\n",
    "train_cuisine_dummies = pd.get_dummies(train.cuisine)\n",
    "train = pd.concat([train[['Restaurant_Name', 'Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], train_price_level_dummies], axis = 1)\n",
    "train = pd.concat([train, train_cuisine_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to impute Rating from food_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food_rating\n",
       "4.3    14.0\n",
       "4.4    14.0\n",
       "4.5    14.0\n",
       "4.6    14.0\n",
       "4.7    14.0\n",
       "4.8    16.0\n",
       "4.9    18.0\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('food_rating')['Rating'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Searching for nulls wasn't working so I had fill with a number\n",
    "import numpy as np\n",
    "train['Rating'].fillna(-5.0, inplace=True)\n",
    "\n",
    "for i in range(0,len(train)):\n",
    "    if (train.loc[i,('Rating')] == -5.0) and (train.loc[i,('food_rating')]): \n",
    "        if train.loc[i,('food_rating')] < 4.8:\n",
    "            train.loc[i,('Rating')] = 14.0 #Assume 13.5\n",
    "        elif train.loc[i,('food_rating')] == 4.8:\n",
    "            train.loc[i,('Rating')] = 16.0\n",
    "        else:\n",
    "            train.loc[i,('Rating')] = 18.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food_rating\n",
       "4.4    13.500000\n",
       "4.5    13.676471\n",
       "4.6    14.391304\n",
       "4.7    14.769231\n",
       "4.8    15.500000\n",
       "4.9    15.500000\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.groupby('food_rating')['Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch['Rating'].fillna(-5.0, inplace=True)\n",
    "\n",
    "for i in range(0,len(ch)):\n",
    "    if (ch.loc[i,('Rating')] == -5.0) and (ch.loc[i,('food_rating')]): \n",
    "        if ch.loc[i,('food_rating')] < 4.6:\n",
    "            ch.loc[i,('Rating')] = 13.5\n",
    "        elif ch.loc[i,('food_rating')] <4.8:\n",
    "            ch.loc[i,('Rating')] = 14.5\n",
    "        else:\n",
    "            ch.loc[i,('Rating')] = 15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food_rating\n",
       "4.3    13.968750\n",
       "4.4    13.936170\n",
       "4.5    14.028169\n",
       "4.6    14.026316\n",
       "4.7    14.916667\n",
       "4.8    14.500000\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Used mean as median doesn't give much insight. Median is 14.0 for all food_ratings\n",
    "dc.groupby('food_rating')['Rating'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dc['Rating'].fillna(-5.0, inplace=True)\n",
    "\n",
    "for i in range(0,len(dc)):\n",
    "    if (dc.loc[i,('Rating')] == -5.0) and (dc.loc[i,('food_rating')]): \n",
    "        if dc.loc[i,('food_rating')] < 4.7:\n",
    "            dc.loc[i,('Rating')] = 14.0\n",
    "#        elif dc.loc[i,('food_rating')] < 4.7:\n",
    "#            dc.loc[i,('Rating')] = 13.0 #Assume that 4.4 should be 13.0 as well\n",
    "        else:\n",
    "            dc.loc[i,('Rating')] = 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create dataframe to use for DC predictions\n",
    "dc_price_level_dummies = pd.get_dummies(dc.price_level)\n",
    "dc_cuisine_dummies = pd.get_dummies(dc.cuisine)\n",
    "dc_test = pd.concat([dc[['Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], dc_price_level_dummies], axis = 1)\n",
    "dc_test = pd.concat([dc_test, dc_cuisine_dummies], axis = 1)\n",
    "#dc_test = dc[['Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']]\n",
    "dc_test.dropna(inplace=True)\n",
    "dc_test.reset_index(inplace =True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:17: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n"
     ]
    }
   ],
   "source": [
    "#Keep columns as \n",
    "#ch_price_level_dummies = pd.get_dummies(ch.price_level)\n",
    "#test = pd.concat([ch[['Restaurant_Name', 'Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], price_level_dummies], axis = 1)\n",
    "train.dropna(inplace = True)\n",
    "#X_train = train[['Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']]\n",
    "X_train = train[train.columns -['Restaurant_Name'] - ['Stars']]\n",
    "y_train = train['Stars']\n",
    "\n",
    "ch_price_level_dummies = pd.get_dummies(ch.price_level)\n",
    "ch_cuisine_dummies = pd.get_dummies(ch.cuisine)\n",
    "test = pd.concat([ch[['Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], ch_price_level_dummies], axis = 1)\n",
    "test = pd.concat([test, ch_cuisine_dummies], axis = 1)\n",
    "#test = ch[['Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']]\n",
    "test.dropna(inplace=True)\n",
    "test.reset_index(inplace =True, drop = True)\n",
    "#train[train.columns -['Restaurant_Name'] - ['Stars']]\n",
    "X_test = test[test.columns - ['Stars']]\n",
    "#x_test = test[['Rating', 'cost', 'food_rating','decor_rating', 'service_rating','M', 'VE']]\n",
    "y_test = test['Stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Takes model.predict(dc_test) as input\n",
    "def dc_predictions (x):\n",
    "    dc_result = pd.DataFrame(x)\n",
    "    dc_result.rename(columns = {0:'predicted_stars'}, inplace=True)\n",
    "    dc_dummy = dc_test.reset_index(drop = True)\n",
    "    temp = pd.concat([dc_result, dc_dummy], axis = 1)\n",
    "    dc_final = pd.merge(dc, temp, on =['Rating','cost','food_rating','decor_rating','service_rating'] )\n",
    "    dc_final = dc_final[['Restaurant_Name', 'predicted_stars']]\n",
    "    print '\\n',dc_final[dc_final['predicted_stars'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def run_model(model):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "#     print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "#     print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "#     dc_predictions(model.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must  match the input. Model n_features is 66 and  input n_features is 33 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-7cad66c4562e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Confusion Matrix'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    535\u001b[0m         \"\"\"\n\u001b[0;32m    536\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    317\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    374\u001b[0m                              \u001b[1;34m\" match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                              \u001b[1;34m\" input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must  match the input. Model n_features is 66 and  input n_features is 33 "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(rf.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01130537,  0.        ,  0.00832384,  0.11168003,  0.07101764,\n",
       "        0.43144974,  0.11343065,  0.08021578,  0.17257696])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>cost</th>\n",
       "      <th>food_rating</th>\n",
       "      <th>decor_rating</th>\n",
       "      <th>service_rating</th>\n",
       "      <th>E</th>\n",
       "      <th>I</th>\n",
       "      <th>M</th>\n",
       "      <th>VE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  cost  food_rating  decor_rating  service_rating    E    I    M   VE\n",
       "0    15.0  43.0          4.8           4.1             4.6  0.0  0.0  1.0  0.0\n",
       "1    14.0  52.0          4.8           4.5             4.5  1.0  0.0  0.0  0.0\n",
       "2    15.0  89.0          4.8           4.7             4.7  1.0  0.0  0.0  0.0\n",
       "3    14.0  89.0          4.8           4.5             4.6  1.0  0.0  0.0  0.0\n",
       "4    14.0  52.0          4.8           4.5             4.5  0.0  0.0  1.0  0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 1188 candidates, totalling 7128 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 629 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1195 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1925 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2815 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3869 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5083 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6461 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7128 out of 7128 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.884615384615\n",
      "Confusion Matrix \n",
      "[[63  1  1  0]\n",
      " [ 5  5  0  0]\n",
      " [ 0  2  0  0]\n",
      " [ 0  0  0  1]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.97      0.95        65\n",
      "        1.0       0.62      0.50      0.56        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.87      0.88      0.87        78\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 3,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 8}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20], 'criterion':['gini', 'entropy'], 'max_depth':[3,5,7,10,12,15], 'min_samples_split': [2,3,4], 'min_samples_leaf':[1,2,3] }\n",
    "gsrf = GridSearchCV(RandomForestClassifier(), param_grid, verbose = 2, cv= 6, n_jobs = -1)\n",
    "gsrf.fit(X_train, y_train)\n",
    "y_pred = gsrf.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "gsrf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Restaurant_Name  predicted_stars\n",
      "10        minibar by josé andrés              3.0\n",
      "15  marcel's by robert wiedmaier              1.0\n",
      "46                          komi              1.0\n"
     ]
    }
   ],
   "source": [
    "rf_best = RandomForestClassifier(criterion= 'gini', max_depth= 3, min_samples_leaf= 2, min_samples_split = 3, n_estimators = 8)\n",
    "rf_best.fit(X_train, y_train)\n",
    "y_pred = rf_best.predict(X_test)\n",
    "dc_predictions(rf_best.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17471019,  0.3768604 ,  0.15173182,  0.05053022,  0.24616737])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>cost</th>\n",
       "      <th>decor_rating</th>\n",
       "      <th>food_rating</th>\n",
       "      <th>service_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  cost  decor_rating  food_rating  service_rating\n",
       "0    13.0  43.0           3.8          4.5             4.2"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.columns -['Restaurant_Name'] - ['Stars']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.820512820513\n",
      "Confusion Matrix \n",
      "[[63  1  1  0]\n",
      " [ 8  1  0  1]\n",
      " [ 1  1  0  0]\n",
      " [ 0  0  1  0]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.97      0.92        65\n",
      "        1.0       0.33      0.10      0.15        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.77      0.82      0.79        78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "ex = ExtraTreesClassifier()\n",
    "ex.fit(X_train, y_train)\n",
    "y_pred = ex.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "dc_predictions(ex.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2310 candidates, totalling 6930 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 571 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1137 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1867 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2757 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3811 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5025 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6403 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6930 out of 6930 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.871794871795\n",
      "Confusion Matrix \n",
      "[[63  1  1  0]\n",
      " [ 5  4  0  1]\n",
      " [ 1  1  0  0]\n",
      " [ 0  0  0  1]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94        65\n",
      "        1.0       0.67      0.40      0.50        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       0.50      1.00      0.67         1\n",
      "\n",
      "avg / total       0.85      0.87      0.86        78\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 12,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 9}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20], 'criterion':['gini', 'entropy'], 'max_depth':[None,3,5,7,10,12,15], 'min_samples_split': [2,3,4,5,6], 'min_samples_leaf':[1,2,3] }\n",
    "gsex = GridSearchCV(ExtraTreesClassifier(), param_grid, verbose = 2, n_jobs = -1)\n",
    "gsex.fit(X_train, y_train)\n",
    "y_pred = gsex.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "gsex.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Restaurant_Name  predicted_stars\n",
      "5                     fiola              2.0\n",
      "10   minibar by josé andrés              3.0\n",
      "19                    plume              3.0\n",
      "27                lightfoot              1.0\n",
      "46                     komi              1.0\n",
      "154       sakedokoro makoto              1.0\n"
     ]
    }
   ],
   "source": [
    "ex_best = ExtraTreesClassifier(criterion='entropy', max_depth = 12, min_samples_leaf = 1, min_samples_split = 6, n_estimators = 9)\n",
    "ex_best.fit(X_train, y_train)\n",
    "y_pred = ex_best.predict(X_test)\n",
    "dc_predictions(ex_best.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.858974358974\n",
      "Confusion Matrix \n",
      "[[64  1  0  0]\n",
      " [ 6  3  0  1]\n",
      " [ 0  2  0  0]\n",
      " [ 0  0  1  0]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.98      0.95        65\n",
      "        1.0       0.50      0.30      0.37        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.83      0.86      0.84        78\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_rbf = svm.SVC()\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "y_pred = svm_rbf.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(svm_rbf.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.833333333333\n",
      "Confusion Matrix \n",
      "[[58  6  1  0]\n",
      " [ 5  5  0  0]\n",
      " [ 0  1  1  0]\n",
      " [ 0  0  0  1]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.89      0.91        65\n",
      "        1.0       0.42      0.50      0.45        10\n",
      "        2.0       0.50      0.50      0.50         2\n",
      "        3.0       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.85      0.83      0.84        78\n",
      "\n",
      "\n",
      "                                    Restaurant_Name  predicted_stars\n",
      "0                      monocacy crossing restaurant              1.0\n",
      "1                                   rasika west end              1.0\n",
      "2                                   rasika west end              1.0\n",
      "3                                            rasika              1.0\n",
      "4                                            rasika              1.0\n",
      "5                                             fiola              1.0\n",
      "6                                          corduroy              1.0\n",
      "7                           l'auberge chez francois              1.0\n",
      "8                 fogo de chão brazilian steakhouse              1.0\n",
      "9                                             tosca              1.0\n",
      "10                           minibar by josé andrés              1.0\n",
      "11                                    the lafayette              1.0\n",
      "12                                  the bombay club              1.0\n",
      "13                                        prime rib              1.0\n",
      "14                                        pupatella              1.0\n",
      "15                     marcel's by robert wiedmaier              1.0\n",
      "16                                          red hen              1.0\n",
      "17                                         zaytinya              1.0\n",
      "18                                    rose's luxury              1.0\n",
      "19                                            plume              1.0\n",
      "20                          rappahannock oyster bar              1.0\n",
      "21                                         menomale              1.0\n",
      "22                                     kabob palace              1.0\n",
      "23                             florida avenue grill              1.0\n",
      "24                                   mintwood place              1.0\n",
      "25                                          donburi              1.0\n",
      "26                                              sei              1.0\n",
      "27                                        lightfoot              1.0\n",
      "28                           central michel richard              1.0\n",
      "29                                 ayse meze lounge              1.0\n",
      "..                                              ...              ...\n",
      "262                al dente italian restaurant d.c.              1.0\n",
      "263                                            etto              1.0\n",
      "264                                   mari vanna dc              1.0\n",
      "265                                     pi pizzeria              1.0\n",
      "266                                     pi pizzeria              1.0\n",
      "267                                pi pizzeria - dc              1.0\n",
      "268                                pi pizzeria - dc              1.0\n",
      "269                     banana cafe &amp; piano bar              1.0\n",
      "270                                   big bear cafe              1.0\n",
      "271                 honey pig gooldaegee korean bbq              1.0\n",
      "272                                 georgia brown's              1.0\n",
      "273                                           mandu              1.0\n",
      "274                                          rakuya              1.0\n",
      "275                                          rakuya              1.0\n",
      "276                                            raku              1.0\n",
      "277                                            raku              1.0\n",
      "278                                  ardeo + bardeo              1.0\n",
      "279                               sichuan jin river              1.0\n",
      "280                                           range              1.0\n",
      "281                   fire works pizza - courthouse              1.0\n",
      "282                   fire works pizza - courthouse              1.0\n",
      "283                                      fire works              1.0\n",
      "284                                      fire works              1.0\n",
      "285                               tavira restaurant              1.0\n",
      "286                                       bar pilar              1.0\n",
      "287                                  woodward table              1.0\n",
      "288                          minerva indian cuisine              1.0\n",
      "289                               bobby van's grill              1.0\n",
      "290  mccormick &amp; schmick's seafood &amp; steaks              1.0\n",
      "291                                         bond 45              1.0\n",
      "\n",
      "[292 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(dt.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.858974358974\n",
      "Confusion Matrix \n",
      "[[63  2  0  0]\n",
      " [ 6  2  2  0]\n",
      " [ 0  1  1  0]\n",
      " [ 0  0  0  1]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94        65\n",
      "        1.0       0.40      0.20      0.27        10\n",
      "        2.0       0.33      0.50      0.40         2\n",
      "        3.0       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.83      0.86      0.84        78\n",
      "\n",
      "\n",
      "                                    Restaurant_Name  predicted_stars\n",
      "0                      monocacy crossing restaurant              1.0\n",
      "1                                   rasika west end              1.0\n",
      "2                                   rasika west end              1.0\n",
      "3                                            rasika              1.0\n",
      "4                                            rasika              1.0\n",
      "5                                             fiola              1.0\n",
      "6                                          corduroy              1.0\n",
      "7                           l'auberge chez francois              1.0\n",
      "8                 fogo de chão brazilian steakhouse              1.0\n",
      "9                                             tosca              1.0\n",
      "10                           minibar by josé andrés              1.0\n",
      "11                                    the lafayette              1.0\n",
      "12                                  the bombay club              1.0\n",
      "13                                        prime rib              1.0\n",
      "14                                        pupatella              1.0\n",
      "15                     marcel's by robert wiedmaier              1.0\n",
      "16                                          red hen              1.0\n",
      "17                                         zaytinya              1.0\n",
      "18                                    rose's luxury              1.0\n",
      "19                                            plume              1.0\n",
      "20                          rappahannock oyster bar              1.0\n",
      "21                                         menomale              1.0\n",
      "22                                     kabob palace              1.0\n",
      "23                             florida avenue grill              1.0\n",
      "24                                   mintwood place              1.0\n",
      "25                                          donburi              1.0\n",
      "26                                              sei              1.0\n",
      "27                                        lightfoot              1.0\n",
      "28                           central michel richard              1.0\n",
      "29                                 ayse meze lounge              1.0\n",
      "..                                              ...              ...\n",
      "262                al dente italian restaurant d.c.              1.0\n",
      "263                                            etto              1.0\n",
      "264                                   mari vanna dc              1.0\n",
      "265                                     pi pizzeria              1.0\n",
      "266                                     pi pizzeria              1.0\n",
      "267                                pi pizzeria - dc              1.0\n",
      "268                                pi pizzeria - dc              1.0\n",
      "269                     banana cafe &amp; piano bar              1.0\n",
      "270                                   big bear cafe              1.0\n",
      "271                 honey pig gooldaegee korean bbq              1.0\n",
      "272                                 georgia brown's              1.0\n",
      "273                                           mandu              1.0\n",
      "274                                          rakuya              1.0\n",
      "275                                          rakuya              1.0\n",
      "276                                            raku              1.0\n",
      "277                                            raku              1.0\n",
      "278                                  ardeo + bardeo              1.0\n",
      "279                               sichuan jin river              1.0\n",
      "280                                           range              1.0\n",
      "281                   fire works pizza - courthouse              1.0\n",
      "282                   fire works pizza - courthouse              1.0\n",
      "283                                      fire works              1.0\n",
      "284                                      fire works              1.0\n",
      "285                               tavira restaurant              1.0\n",
      "286                                       bar pilar              1.0\n",
      "287                                  woodward table              1.0\n",
      "288                          minerva indian cuisine              1.0\n",
      "289                               bobby van's grill              1.0\n",
      "290  mccormick &amp; schmick's seafood &amp; steaks              1.0\n",
      "291                                         bond 45              1.0\n",
      "\n",
      "[292 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bdt = BaggingClassifier(DecisionTreeClassifier())\n",
    "bdt.fit(X_train, y_train)\n",
    "y_pred = bdt.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(bdt.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.884615384615\n",
      "Confusion Matrix \n",
      "[[65  0  0  0]\n",
      " [ 7  3  0  0]\n",
      " [ 1  1  0  0]\n",
      " [ 0  0  0  1]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      1.00      0.94        65\n",
      "        1.0       0.75      0.30      0.43        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.85      0.88      0.85        78\n",
      "\n",
      "\n",
      "           Restaurant_Name  predicted_stars\n",
      "10  minibar by josé andrés              3.0\n",
      "46                    komi              1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(lr.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.0128205128205\n",
      "Confusion Matrix \n",
      "[[ 0  0  0 65]\n",
      " [ 0  0  0 10]\n",
      " [ 0  0  0  2]\n",
      " [ 0  0  0  1]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        65\n",
      "        1.0       0.00      0.00      0.00        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       0.01      1.00      0.03         1\n",
      "\n",
      "avg / total       0.00      0.01      0.00        78\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "kn = KNeighborsClassifier()\n",
    "kn.fit(X_train, y_train)\n",
    "y_pred = kn.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(kn.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "dc_predictions(kn.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Failures...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_app_id = 'vKNIMUrgB4Q1bw9QQBrWvA'\n",
    "yelp_secret = '47e2cwloU2D3yjjn8ZNW19coWnzty42bjLpy4Nr3tKxTLb8XamT6dM5cpYdqQDUt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'json_loads'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c73ded2b0e67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#Transforms the JSON API response into a Python dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mz\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_loads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;31m#data['businesses']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'json_loads'"
     ]
    }
   ],
   "source": [
    "from yelpapi import YelpAPI\n",
    "import rauth\n",
    "\n",
    "yelp_key = 'h7PhOS6JV0P-q_HBqhPcNA'\n",
    "yelp_secret = '-cvy8PzcSI-PuAa9nTifCNoPkN8'\n",
    "yelp_token = 'jOBN_KgzD6pnrkqWldAxV-bD7O5zUFLh'\n",
    "yelp_token_secret = 'ywnyhjQ6nFhUXPAl1dbSpooT5LQ'\n",
    "#yelp_api = YelpAPI(yelp_key, yelp_secret, yelp_token, yelp_token_secret)\n",
    "session = rauth.OAuth1Session(\n",
    "    consumer_key = yelp_key\n",
    "    ,consumer_secret = yelp_secret\n",
    "    ,access_token = yelp_token\n",
    "    ,access_token_secret = yelp_token_secret)\n",
    "\n",
    "params = {}\n",
    "params[\"term\"] = \"restaurant\"\n",
    "params[\"location\"] = \"San Francisco\"\n",
    "#params[\"limit\"] = 20\n",
    "request = session.get(\"http://api.yelp.com/v2/search\",params=params)\n",
    "   \n",
    "#Transforms the JSON API response into a Python dictionary\n",
    "data = request.json()\n",
    "z= pd.json_loads(data)\n",
    "#data['businesses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Pizza Boli\\u2019s',\n",
       " u'Rose\\u2019s Luxury',\n",
       " u'Keren Restaurant',\n",
       " u'Komi',\n",
       " u'Neopol Savory Smokery',\n",
       " u'Nido',\n",
       " u'Timber Pizza Company',\n",
       " u'Bub and Pop\\u2019s',\n",
       " u'Chaia',\n",
       " u'Rasika',\n",
       " u'Pennsylvania 6 DC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_url = 'https://www.yelp.com/search?find_desc=Restaurants&find_loc=Washington,+DC&start=0&sortby=rating&attrs=RestaurantsPriceRange2.2,RestaurantsPriceRange2.3,RestaurantsPriceRange2.4'\n",
    "r = requests.get(yelp_url)\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "\n",
    "def yelp_restaurant_name (soup):\n",
    "    name = []\n",
    "    for row in soup.findAll('a', {'data-analytics-label':'biz-name'}):\n",
    "        try:\n",
    "            name.append(row.getText())\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return name\n",
    "\n",
    "yelp_restaurant_name(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
