{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from urlparse import urljoin\n",
    "import urllib\n",
    "import urllib2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.viamichelin.com/web/Restaurants/Restaurants-United_States?page=1'\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def michelin_restaurant_name (soup):\n",
    "    name = []\n",
    "    for row in soup.findAll('div', {'class':'poi-item-name truncate'}):\n",
    "        try:\n",
    "            name.append(row.getText().strip('\\n'))\n",
    "            \n",
    "        except:\n",
    "            name.append(\"NA\")\n",
    "    return name\n",
    "\n",
    "def address (soup):\n",
    "    address = []\n",
    "    for row in soup.findAll('div', {'class':'poi-item-address truncate'}):\n",
    "        try:\n",
    "            address.append(row.getText().strip('\\n').strip('\\t').strip('\\n'))\n",
    "            \n",
    "        except:\n",
    "            address.append(\"NA\")\n",
    "    return address\n",
    "\n",
    "def stars (soup):\n",
    "    star = []\n",
    "    for row in soup.findAll(lambda tag: tag.name == 'span' and tag.get('class') == ['poi-item-stars']):\n",
    "        count = 0\n",
    "        try:\n",
    "            for cnt in row.findAll('span', {'class':'star'}):\n",
    "                count = count+1\n",
    "            star.append(count)\n",
    "        except:\n",
    "            star.append(count)\n",
    "    return star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for page in range(1,72):\n",
    "    url = 'https://www.viamichelin.com/web/Restaurants/Restaurants-United_States?page='+str(page)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "    name_df = pd.DataFrame(michelin_restaurant_name(soup), columns = ['Restaurant_Name'])\n",
    "    address_df= pd.DataFrame(address(soup), columns = ['Address'])\n",
    "    star_df = pd.DataFrame(stars(soup), columns = ['Stars'])\n",
    "    aggregate = pd.concat([name_df, address_df, star_df], axis = 1)\n",
    "    results = results.append(aggregate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\Michelin_Restaurants.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gayot\n",
    "location = 'NY'\n",
    "page = 0\n",
    "gayot_url = 'http://www.gayot.com/restaurants/searchresult.php?search=&rating=13&code=NY&start=50&jump='\n",
    "r = requests.get(gayot_url)\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gayot_restaurant_name(soup):\n",
    "    name = []\n",
    "    for row in soup.findAll('a', {'class':'hoveru'}):\n",
    "        try:\n",
    "            name.append(row.getText())\n",
    "            \n",
    "        except:\n",
    "            name.append(\"NA\")\n",
    "    return name\n",
    "\n",
    "def gayot_rating(soup):\n",
    "    rating = []\n",
    "    \n",
    "    for row in soup.findAll('td', {'width': '100'}):\n",
    "        try:\n",
    "            if row.find('strong').getText() is not None:\n",
    "                #Orginal format was '13/20'. Pulled out score and convert to float\n",
    "                rating.append(float(row.find('strong').getText()[0:2]))\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return rating\n",
    "\n",
    "def gayot_address(soup):\n",
    "    address = []\n",
    "    for row in soup.findAll('td', {'width': '278'}):\n",
    "        try:\n",
    "            #Pull address and remove extra tags/characters\n",
    "            address.append(row.getText()[2:len(row.getText())-11])\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gayot_address(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for city in ['NY']: #Come back and do NY, 140 for CH, 760 for NY\n",
    "    for rating in range(12,21): #Start with rating 12 as 10 and 11 are too low for Michelin\n",
    "        for page in range(0,760,10): #The max number of listings per rating per city is 762 (NY with rating 13)\n",
    "            gayot_url = 'http://www.gayot.com/restaurants/searchresult.php?search=&rating='+str(rating)+'&code='+str(city)+'&start='+str(page)+'&jump='\n",
    "            r = requests.get(gayot_url)\n",
    "            soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "            name_df = pd.DataFrame(gayot_restaurant_name(soup), columns = ['Restaurant_Name'])\n",
    "            address_df= pd.DataFrame(gayot_address(soup), columns = ['Address'])\n",
    "            rating_df = pd.DataFrame(gayot_rating(soup), columns = ['Rating'])\n",
    "            aggregate = pd.concat([name_df, address_df, rating_df], axis = 1)\n",
    "            results = results.append(aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\NY_Gayot_Restaurants.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zagat_url = 'https://www.zagat.com/p/washington-dc#filter/addr_city=Washington&score5_food=4.0&vertical=46&orderby=score_food&sort=desc&page=2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(zagat_url)\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "\n",
    "def zagat_restaurant_name (soup):\n",
    "    name = []\n",
    "    for row in soup.findAll('span', {'class':'content-card__link js-hover-apply'}):\n",
    "        try:\n",
    "            name.append(row.getText())\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return name\n",
    "\n",
    "def zagat_rating(soup):\n",
    "    rating = []\n",
    "    \n",
    "    for row in soup.findAll('td', {'width': '100'}):\n",
    "        try:\n",
    "            if row.find('strong').getText() is not None:\n",
    "                #Orginal format was '13/20'. Pulled out score and convert to float\n",
    "                rating.append(float(row.find('strong').getText()[0:2]))\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import urllib\n",
    "import sqlite3\n",
    "\n",
    "sf = pd.DataFrame()\n",
    "for page in range(1, 50):\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1021&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    sf = sf.append(cityadd)\n",
    "\n",
    "sf = sf.reset_index()\n",
    "del sf['index']\n",
    "\n",
    "ny = pd.DataFrame()\n",
    "for page in range(1, 50):\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1020&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    ny = ny.append(cityadd)\n",
    "\n",
    "ny = ny.reset_index()\n",
    "del ny['index']\n",
    "\n",
    "#Get fewer cities for CH and DC as they are smaller cities. Don't want too much class imbalance\n",
    "ch = pd.DataFrame()\n",
    "for page in range(1, 25):\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1013&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    ch = ch.append(cityadd)\n",
    "\n",
    "ch = ch.reset_index()\n",
    "del ch['index']\n",
    "\n",
    "dc = pd.DataFrame()\n",
    "for page in range(1, 25):\n",
    "    #zagat_url= \"https://www.zagat.com/proxy/v1.4?addr_city=Washington&score5_food=4.0&vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1024&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    zagat_url= \"https://www.zagat.com/proxy/v1.4?vertical=46&orderby=score_food&sort=desc&page=\"+str(page)+\"&city=1024&query=&key=abbc09b7c840c10937a4db331422c98b&mobile_only_content=false&limit=15&m=filter&a=place\"\n",
    "    html = urllib.urlopen(zagat_url).read()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    city=json.loads(str(soup))\n",
    "    cityadd = pd.DataFrame(city[\"data\"])\n",
    "    food = pd.DataFrame()\n",
    "    decor = pd.DataFrame()\n",
    "    service = pd.DataFrame()\n",
    "    for row in range (0,len(city[\"data\"])):\n",
    "        food = food.append(pd.Series(city['data'][row]['score']['score5_food']),ignore_index=True)\n",
    "        decor = decor.append(pd.Series(city['data'][row]['score']['score5_decor']),ignore_index=True)\n",
    "        service = service.append(pd.Series(city['data'][row]['score']['score5_service']),ignore_index=True)\n",
    "    cityadd['food_rating'] = food\n",
    "    cityadd['decor_rating'] = decor\n",
    "    cityadd['service_rating'] = service\n",
    "    dc = dc.append(cityadd)\n",
    "\n",
    "dc = dc.reset_index()\n",
    "del dc['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['title', 'cuisine', 'cost', 'price_level', 'food_rating', 'decor_rating', 'service_rating']\n",
    "sf = sf[columns]\n",
    "ny = ny[columns]\n",
    "ch = ch[columns]\n",
    "dc = dc[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\NY_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')\n",
    "sf.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\SF_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')\n",
    "ch.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\CH_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')\n",
    "dc.to_csv(r'C:\\Users\\An\\Desktop\\DSI-DC-2\\Portfolio\\Michelin\\DC_Zagat_Restaurants.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read, standardize and join csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny_gayot = pd.read_csv('NY_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "sf_gayot = pd.read_csv('SF_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "ch_gayot = pd.read_csv('CH_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "dc_gayot = pd.read_csv('DC_Gayot_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "ny_zagat = pd.read_csv('NY_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "sf_zagat = pd.read_csv('SF_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "ch_zagat = pd.read_csv('CH_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "dc_zagat = pd.read_csv('DC_Zagat_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "\n",
    "michelin = pd.read_csv('Michelin_Restaurants.csv',sep='\\t', encoding='utf-8')\n",
    "award = pd.read_csv('James_Beard_Awards.csv')\n",
    "\n",
    "ny_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "ch_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "sf_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "dc_zagat.rename(columns = {'title':'Restaurant_Name'}, inplace = True)\n",
    "ny_gayot['Restaurant_Name'] = ny_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "ch_gayot['Restaurant_Name'] = ch_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "sf_gayot['Restaurant_Name'] = sf_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "dc_gayot['Restaurant_Name'] = dc_gayot['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "ny_zagat['Restaurant_Name'] = ny_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "ch_zagat['Restaurant_Name'] = ch_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "dc_zagat['Restaurant_Name'] = dc_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "sf_zagat['Restaurant_Name'] = sf_zagat['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "michelin['Restaurant_Name'] = michelin['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "award['Restaurant_Name'] = award['Restaurant_Name'].map(lambda x: x.lower().lstrip().rstrip())\n",
    "\n",
    "#Drop chain restaurants\n",
    "ny_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "ch_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "sf_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "dc_gayot.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "ny_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "ch_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "sf_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "dc_zagat.drop_duplicates(['Restaurant_Name'],keep=False, inplace = True)\n",
    "\n",
    "ny_gayot.reset_index(inplace=True, drop = True)\n",
    "ch_gayot.reset_index(inplace=True, drop = True)\n",
    "sf_gayot.reset_index(inplace=True, drop = True)\n",
    "dc_gayot.reset_index(inplace=True, drop = True)\n",
    "ny_zagat.reset_index(inplace=True, drop = True)\n",
    "ch_zagat.reset_index(inplace=True, drop = True)\n",
    "sf_zagat.reset_index(inplace=True, drop = True)\n",
    "dc_zagat.reset_index(inplace=True, drop = True)\n",
    "michelin.reset_index(inplace=True, drop = True)\n",
    "\n",
    "del ny_gayot['Unnamed: 0']\n",
    "del sf_gayot['Unnamed: 0']\n",
    "del ch_gayot['Unnamed: 0']\n",
    "del dc_gayot['Unnamed: 0']\n",
    "del ny_zagat['Unnamed: 0']\n",
    "del sf_zagat['Unnamed: 0']\n",
    "del ch_zagat['Unnamed: 0']\n",
    "del dc_zagat['Unnamed: 0']\n",
    "del michelin['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def zip(x):\n",
    "    return x[len(x)-5:len(x)]\n",
    "\n",
    "michelin['zip']= michelin['Address'].map(zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ny (x):\n",
    "    if (x[0]=='1'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def ch (x):\n",
    "    if (x[0]=='6') or (x=='icago'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def sf (x):\n",
    "    if (x[0] == '9'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Indicates City of the row\n",
    "michelin['ny'] = michelin['zip'].apply(ny)\n",
    "michelin['ch'] = michelin['zip'].apply(ch)\n",
    "michelin['sf'] = michelin['zip'].apply(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ny = pd.merge(michelin[michelin['ny']==1], ny_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "ny = pd.merge(ny, ny_zagat, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "sf = pd.merge(michelin[michelin['sf']==1], sf_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "sf = pd.merge(sf, sf_zagat, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "ch = pd.merge(michelin[michelin['ch']==1], ch_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "ch = pd.merge(ch, ch_zagat, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "dc = pd.merge(dc_zagat, dc_gayot, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "\n",
    "ny = pd.merge(ny, award, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "sf = pd.merge(sf, award, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "ch = pd.merge(ch, award, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "dc = pd.merge(dc, award, left_on = 'Restaurant_Name', right_on = 'Restaurant_Name', how = 'left')\n",
    "\n",
    "ny['Award_Past_Three_Years'].fillna(value = 0, inplace = True)\n",
    "sf['Award_Past_Three_Years'].fillna(value = 0, inplace = True)\n",
    "ch['Award_Past_Three_Years'].fillna(value = 0, inplace = True)\n",
    "dc['Award_Past_Three_Years'].fillna(value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11439114391143912"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny['Stars'].sum()/len(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13598326359832635"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf['Stars'].sum()/len(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09491525423728814"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch['Stars'].sum()/len(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Drop major non-DC restaurants\n",
    "dc = dc[dc['Restaurant_Name']!='the inn at little washington']\n",
    "dc = dc[dc['Restaurant_Name']!='restaurant eve']\n",
    "dc = dc[dc['Restaurant_Name']!='chima brazilian steakhouse']\n",
    "dc = dc[dc['Restaurant_Name']!='tachibana japanese restaurant']\n",
    "\n",
    "dc.drop_duplicates(['Restaurant_Name'], keep=False, inplace = True)\n",
    "dc.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.concat([ny,sf], ignore_index = True)[['Restaurant_Name', 'Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating', 'Award_Past_Three_Years']]\n",
    "#price_level_dummies = pd.get_dummies(train.price_level)\n",
    "#train = pd.concat([train[['Restaurant_Name', 'Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], price_level_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to impute Rating from food_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food_rating\n",
       "4.3    14.0\n",
       "4.4    14.0\n",
       "4.5    14.0\n",
       "4.6    14.0\n",
       "4.7    14.0\n",
       "4.8    16.0\n",
       "4.9    18.0\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('food_rating')['Rating'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Searching for nulls wasn't working so I had fill with a number\n",
    "import numpy as np\n",
    "train['Rating'].fillna(-5.0, inplace=True)\n",
    "\n",
    "# for i in range(0,len(train)):\n",
    "#     if (train.loc[i,('Rating')] == -5.0) and (train.loc[i,('food_rating')]): \n",
    "#         if train.loc[i,('food_rating')] < 4.8:\n",
    "#             train.loc[i,('Rating')] = 14.0 #Assume 13.5\n",
    "#         elif train.loc[i,('food_rating')] == 4.8:\n",
    "#             train.loc[i,('Rating')] = 16.0\n",
    "#         else:\n",
    "#             train.loc[i,('Rating')] = 18.0\n",
    "\n",
    "for i in range(0,len(train)):\n",
    "    if (train.loc[i,('Rating')] == -5.0) and (train.loc[i,('food_rating')]): \n",
    "        if train.loc[i,('food_rating')] < 4.7:\n",
    "            train.loc[i,('Rating')] = 14.0 #Assume 13.5\n",
    "        elif train.loc[i,('food_rating')] == 4.7:\n",
    "            train.loc[i,('Rating')] = 14.5\n",
    "        elif train.loc[i,('food_rating')] == 4.8:\n",
    "            train.loc[i,('Rating')] = 16.5\n",
    "        else:\n",
    "            train.loc[i,('Rating')] = 17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food_rating\n",
       "4.4          NaN\n",
       "4.5    13.833333\n",
       "4.6    14.307692\n",
       "4.7    14.818182\n",
       "4.8    15.500000\n",
       "4.9          NaN\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.groupby('food_rating')['Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch['Rating'].fillna(-5.0, inplace=True)\n",
    "\n",
    "for i in range(0,len(ch)):\n",
    "    if (ch.loc[i,('Rating')] == -5.0) and (ch.loc[i,('food_rating')]): \n",
    "        if ch.loc[i,('food_rating')] < 4.6:\n",
    "            ch.loc[i,('Rating')] = 13.5\n",
    "        elif ch.loc[i,('food_rating')] <4.8:\n",
    "            ch.loc[i,('Rating')] = 14.5\n",
    "        else:\n",
    "            ch.loc[i,('Rating')] = 15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food_rating\n",
       "4.3    13.666667\n",
       "4.4    13.600000\n",
       "4.5    14.133333\n",
       "4.6    14.111111\n",
       "4.7    14.800000\n",
       "4.8    14.250000\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Used mean as median doesn't give much insight. Median is 14.0 for all food_ratings\n",
    "dc.groupby('food_rating')['Rating'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dc['Rating'].fillna(-5.0, inplace=True)\n",
    "\n",
    "for i in range(0,len(dc)):\n",
    "    if (dc.loc[i,('Rating')] == -5.0) and (dc.loc[i,('food_rating')]): \n",
    "        if dc.loc[i,('food_rating')] < 4.7:\n",
    "            dc.loc[i,('Rating')] = 14.0\n",
    "#        elif dc.loc[i,('food_rating')] < 4.7:\n",
    "#            dc.loc[i,('Rating')] = 13.0 #Assume that 4.4 should be 13.0 as well\n",
    "        else:\n",
    "            dc.loc[i,('Rating')] = 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe to use for DC predictions\n",
    "#dc_price_level_dummies = pd.get_dummies(dc.price_level)\n",
    "#dc_test = pd.concat([dc[['Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], dc_price_level_dummies], axis = 1)\n",
    "dc_test = dc[['Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating', 'Award_Past_Three_Years']]\n",
    "dc_test.dropna(inplace=True)\n",
    "dc_test.reset_index(inplace =True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:14: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n"
     ]
    }
   ],
   "source": [
    "#Keep columns as \n",
    "#ch_price_level_dummies = pd.get_dummies(ch.price_level)\n",
    "#test = pd.concat([ch[['Restaurant_Name', 'Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], price_level_dummies], axis = 1)\n",
    "train.dropna(inplace = True)\n",
    "#X_train = train[['Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']]\n",
    "X_train = train[train.columns -['Restaurant_Name'] - ['Stars']]\n",
    "y_train = train['Stars']\n",
    "\n",
    "#ch_price_level_dummies = pd.get_dummies(ch.price_level)\n",
    "#test = pd.concat([ch[['Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating']], ch_price_level_dummies], axis = 1)\n",
    "test = ch[['Stars', 'Rating', 'cost', 'food_rating', 'decor_rating', 'service_rating', 'Award_Past_Three_Years']]\n",
    "test.dropna(inplace=True)\n",
    "#train[train.columns -['Restaurant_Name'] - ['Stars']]\n",
    "X_test = test[test.columns - ['Stars']]\n",
    "#x_test = test[['Rating', 'cost', 'food_rating','decor_rating', 'service_rating','M', 'VE']]\n",
    "y_test = test['Stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Takes model.predict(dc_test) as input\n",
    "def dc_predictions (x):\n",
    "    dc_result = pd.DataFrame(x)\n",
    "    dc_result.rename(columns = {0:'predicted_stars'}, inplace=True)\n",
    "    dc_dummy = dc_test.reset_index(drop = True)\n",
    "    temp = pd.concat([dc_result, dc_dummy], axis = 1)\n",
    "    dc_final = pd.merge(dc, temp, on =['Rating','cost','food_rating','decor_rating','service_rating'] )\n",
    "    dc_final = dc_final[['Restaurant_Name', 'predicted_stars']]\n",
    "    print '\\n',dc_final[dc_final['predicted_stars'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.820512820513\n",
      "Confusion Matrix \n",
      "[[60  4  1  0]\n",
      " [ 5  4  1  0]\n",
      " [ 0  2  0  0]\n",
      " [ 0  0  1  0]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.92      0.92        65\n",
      "        1.0       0.40      0.40      0.40        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.82      0.82      0.82        78\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "rf = RandomForestClassifier(class_weight = 'balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(rf.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20], 'criterion':['gini', 'entropy'], 'max_depth':[3,5,7,10,12,15], 'min_samples_split': [2,3,4], 'min_samples_leaf':[1,2,3] }\n",
    "gsrf = GridSearchCV(RandomForestClassifier(), param_grid, verbose = 2, cv= 6, n_jobs = -1)\n",
    "gsrf.fit(X_train, y_train)\n",
    "y_pred = gsrf.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "gsrf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(criterion= 'gini', max_depth= 3, min_samples_leaf= 2, min_samples_split = 3, n_estimators = 8)\n",
    "rf_best.fit(X_train, y_train)\n",
    "y_pred = rf_best.predict(X_test)\n",
    "dc_predictions(rf_best.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_best.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[train.columns -['Restaurant_Name'] - ['Stars']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.884615384615\n",
      "Confusion Matrix \n",
      "[[62  2  1  0]\n",
      " [ 4  5  1  0]\n",
      " [ 0  1  1  0]\n",
      " [ 0  0  0  1]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.95      0.95        65\n",
      "        1.0       0.62      0.50      0.56        10\n",
      "        2.0       0.33      0.50      0.40         2\n",
      "        3.0       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.88      0.88      0.88        78\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "ex = ExtraTreesClassifier()\n",
    "ex.fit(X_train, y_train)\n",
    "y_pred = ex.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(ex.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-55a5e6d3be09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'criterion'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'entropy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_samples_split'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_samples_leaf'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgsex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgsex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgsex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20], 'criterion':['gini', 'entropy'], 'max_depth':[None,3,5,7,10,12,15], 'min_samples_split': [2,3,4,5,6], 'min_samples_leaf':[1,2,3] }\n",
    "gsex = GridSearchCV(ExtraTreesClassifier(), param_grid, verbose = 2, n_jobs = -1)\n",
    "gsex.fit(X_train, y_train)\n",
    "y_pred = gsex.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "gsex.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex_best = ExtraTreesClassifier(criterion='entropy', max_depth = 12, min_samples_leaf = 1, min_samples_split = 6, n_estimators = 9)\n",
    "ex_best.fit(X_train, y_train)\n",
    "y_pred = ex_best.predict(X_test)\n",
    "dc_predictions(ex_best.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.846153846154\n",
      "Confusion Matrix \n",
      "[[64  1  0  0]\n",
      " [ 7  2  0  1]\n",
      " [ 0  2  0  0]\n",
      " [ 0  0  1  0]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.98      0.94        65\n",
      "        1.0       0.40      0.20      0.27        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.80      0.85      0.82        78\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_rbf = svm.SVC()\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "y_pred = svm_rbf.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(svm_rbf.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_l = svm.SVC(kernel = 'linear')\n",
    "svm_l.fit(X_train, y_train)\n",
    "y_pred = svm_l.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(svm_l.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_p = svm.SVC(kernel = 'poly')\n",
    "svm_p.fit(X_train, y_train)\n",
    "y_pred = svm_p.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(svm_p.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.846153846154\n",
      "Confusion Matrix \n",
      "[[60  4  1  0]\n",
      " [ 6  4  0  0]\n",
      " [ 0  1  1  0]\n",
      " [ 0  0  0  1]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.92      0.92        65\n",
      "        1.0       0.44      0.40      0.42        10\n",
      "        2.0       0.50      0.50      0.50         2\n",
      "        3.0       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.84      0.85      0.84        78\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(dt.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.858974358974\n",
      "Confusion Matrix \n",
      "[[61  3  1  0]\n",
      " [ 5  5  0  0]\n",
      " [ 0  1  1  0]\n",
      " [ 0  0  1  0]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.94      0.93        65\n",
      "        1.0       0.56      0.50      0.53        10\n",
      "        2.0       0.33      0.50      0.40         2\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.85      0.86      0.85        78\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Restaurant_Name, predicted_stars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bdt = BaggingClassifier(DecisionTreeClassifier())\n",
    "bdt.fit(X_train, y_train)\n",
    "y_pred = bdt.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(bdt.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(lr.predict(dc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.0128205128205\n",
      "Confusion Matrix \n",
      "[[ 0  0  0 65]\n",
      " [ 0  0  0 10]\n",
      " [ 0  0  0  2]\n",
      " [ 0  0  0  1]]\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        65\n",
      "        1.0       0.00      0.00      0.00        10\n",
      "        2.0       0.00      0.00      0.00         2\n",
      "        3.0       0.01      1.00      0.03         1\n",
      "\n",
      "avg / total       0.00      0.01      0.00        78\n",
      "\n",
      "\n",
      "                                    Restaurant_Name  predicted_stars\n",
      "0                      monocacy crossing restaurant              3.0\n",
      "1                                   rasika west end              3.0\n",
      "2                                   rasika west end              3.0\n",
      "3                                            rasika              3.0\n",
      "4                                            rasika              3.0\n",
      "5                                             fiola              3.0\n",
      "6                                          corduroy              3.0\n",
      "7                           l'auberge chez francois              3.0\n",
      "8                 fogo de chão brazilian steakhouse              3.0\n",
      "9                                             tosca              3.0\n",
      "10                           minibar by josé andrés              3.0\n",
      "11                                    the lafayette              3.0\n",
      "12                                  the bombay club              3.0\n",
      "13                                        prime rib              3.0\n",
      "15                     marcel's by robert wiedmaier              3.0\n",
      "16                                          red hen              3.0\n",
      "17                                         zaytinya              3.0\n",
      "18                                    rose's luxury              3.0\n",
      "19                                            plume              3.0\n",
      "20                          rappahannock oyster bar              3.0\n",
      "21                                         menomale              2.0\n",
      "23                             florida avenue grill              2.0\n",
      "24                                   mintwood place              3.0\n",
      "26                                              sei              3.0\n",
      "27                                        lightfoot              3.0\n",
      "28                           central michel richard              3.0\n",
      "29                                 ayse meze lounge              3.0\n",
      "30                                 the tasting room              3.0\n",
      "31                                  rt's restaurant              3.0\n",
      "32                                 dutch's daughter              3.0\n",
      "..                                              ...              ...\n",
      "260            lebanese taverna restaurant pentagon              3.0\n",
      "261            lebanese taverna restaurant pentagon              3.0\n",
      "262                al dente italian restaurant d.c.              3.0\n",
      "263                                            etto              3.0\n",
      "264                                   mari vanna dc              3.0\n",
      "265                                     pi pizzeria              2.0\n",
      "266                                     pi pizzeria              2.0\n",
      "267                                pi pizzeria - dc              2.0\n",
      "268                                pi pizzeria - dc              2.0\n",
      "269                     banana cafe &amp; piano bar              3.0\n",
      "271                 honey pig gooldaegee korean bbq              3.0\n",
      "272                                 georgia brown's              3.0\n",
      "273                                           mandu              3.0\n",
      "274                                          rakuya              3.0\n",
      "275                                          rakuya              3.0\n",
      "276                                            raku              3.0\n",
      "277                                            raku              3.0\n",
      "278                                  ardeo + bardeo              3.0\n",
      "280                                           range              3.0\n",
      "281                   fire works pizza - courthouse              2.0\n",
      "282                   fire works pizza - courthouse              2.0\n",
      "283                                      fire works              2.0\n",
      "284                                      fire works              2.0\n",
      "285                               tavira restaurant              3.0\n",
      "286                                       bar pilar              3.0\n",
      "287                                  woodward table              3.0\n",
      "288                          minerva indian cuisine              2.0\n",
      "289                               bobby van's grill              3.0\n",
      "290  mccormick &amp; schmick's seafood &amp; steaks              3.0\n",
      "291                                         bond 45              3.0\n",
      "\n",
      "[264 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "kn = KNeighborsClassifier()\n",
    "kn.fit(X_train, y_train)\n",
    "y_pred = kn.predict(X_test)\n",
    "print 'Accuracy', accuracy_score(y_test, y_pred)\n",
    "print 'Confusion Matrix','\\n',  confusion_matrix(y_test, y_pred)\n",
    "print 'Classification Report','\\n', classification_report(y_test, y_pred)\n",
    "dc_predictions(kn.predict(dc_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
